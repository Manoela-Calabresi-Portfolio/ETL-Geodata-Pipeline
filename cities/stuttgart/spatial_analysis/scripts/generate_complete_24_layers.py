#!/usr/bin/env python3
"""
Complete 24-Layer Generation Script for Stuttgart
Generates all GeoJSON layers + Kepler dashboard + PNG maps in one run
"""

import sys
from pathlib import Path
import warnings
import json
import numpy as np
import pandas as pd
import geopandas as gpd
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from shapely import wkb
from shapely.geometry import Point, Polygon
import h3

warnings.filterwarnings("ignore", category=UserWarning)

# Add utils to path
sys.path.append('../utils')
from h3_helpers import gdf_polygons_to_h3, h3_to_shapely_geometry

# Configuration
DATA_DIR = Path("../data")
OUTPUT_DIR = Path("../outputs/stuttgart_complete_24_layers")
KEPLER_DIR = OUTPUT_DIR / "kepler_data"
PNG_DIR = OUTPUT_DIR / "png_maps"

# Create output directories
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
KEPLER_DIR.mkdir(parents=True, exist_ok=True)
PNG_DIR.mkdir(parents=True, exist_ok=True)

def load_data():
    """Load all required data files"""
    print("üìÅ Loading data...")
    
    def read_any(p: Path):
        if not p.exists(): 
            print(f"  ‚ö†Ô∏è File not found: {p}")
            return None
        try:
            if p.suffix.lower() in {".geojson", ".json", ".gpkg"}:
                return gpd.read_file(p)
            if p.suffix.lower() == ".parquet":
                df = pd.read_parquet(p)
                if "geometry" in df.columns:
                    # Handle WKB geometry data
                    try:
                        df['geometry'] = df['geometry'].apply(lambda x: wkb.loads(x) if x else None)
                        return gpd.GeoDataFrame(df, geometry='geometry', crs=4326)
                    except Exception as wkb_error:
                        print(f"  ‚ö†Ô∏è WKB conversion failed for {p.name}: {wkb_error}")
                        try:
                            return gpd.GeoDataFrame(df, geometry='geometry', crs=4326)
                        except Exception as gdf_error:
                            print(f"  ‚ùå GeoDataFrame creation failed for {p.name}: {gdf_error}")
                            return None
                return df
        except Exception as e:
            print(f"  ‚ùå Error reading {p}: {e}")
            return None

    data = {
        "districts": read_any(DATA_DIR/"districts_with_population.geojson"),
        "city_boundary": read_any(DATA_DIR/"city_boundary.geojson"),
        "pt_stops": read_any(DATA_DIR/"processed/pt_stops_categorized.parquet"),
        "amenities": read_any(DATA_DIR/"processed/amenities_categorized.parquet"),
        "landuse": read_any(DATA_DIR/"processed/landuse_categorized.parquet"),
        "roads": read_any(DATA_DIR/"processed/roads_categorized.parquet"),
        "h3_population": read_any(DATA_DIR/"h3_population_res8.parquet"),
    }
    
    # Ensure CRS is set
    for k, gdf in data.items():
        if gdf is not None and hasattr(gdf, 'crs'):
            if gdf.crs is None:
                data[k] = gdf.set_crs(4326)
            else:
                data[k] = gdf.to_crs(4326)
    
    return data

def generate_basic_layers(data):
    """Generate basic layers 01-06"""
    print("üó∫Ô∏è Generating basic layers (01-06)...")
    
    # 01 - City Boundary
    if data["city_boundary"] is not None:
        data["city_boundary"].to_file(KEPLER_DIR/"01_city_boundary.geojson", driver="GeoJSON")
        print("  ‚úÖ 01_city_boundary.geojson")
    
    # 02 - Districts
    if data["districts"] is not None:
        data["districts"].to_file(KEPLER_DIR/"02_districts.geojson", driver="GeoJSON")
        print("  ‚úÖ 02_districts.geojson")
    
    # 03 - PT Stops
    if data["pt_stops"] is not None:
        data["pt_stops"].to_file(KEPLER_DIR/"03_pt_stops.geojson", driver="GeoJSON")
        print("  ‚úÖ 03_pt_stops.geojson")
    
    # 04 - Landuse
    if data["landuse"] is not None:
        data["landuse"].to_file(KEPLER_DIR/"04_landuse.geojson", driver="GeoJSON")
        print("  ‚úÖ 04_landuse.geojson")
    
    # 05 - Roads
    if data["roads"] is not None:
        data["roads"].to_file(KEPLER_DIR/"05_roads.geojson", driver="GeoJSON")
        print("  ‚úÖ 05_roads.geojson")
    
    # 06 - H3 Population
    if data["h3_population"] is not None:
        # Convert DataFrame to GeoDataFrame if needed
        if hasattr(data["h3_population"], 'to_file'):
            data["h3_population"].to_file(KEPLER_DIR/"06_h3_population.geojson", driver="GeoJSON")
        else:
            # Create a simple H3 population layer
            h3_pop = create_h3_population_layer()
            h3_pop.to_file(KEPLER_DIR/"06_h3_population.geojson", driver="GeoJSON")
        print("  ‚úÖ 06_h3_population.geojson")

def generate_h3_analysis_layers(data):
    """Generate H3 analysis layers 13-17"""
    print("üó∫Ô∏è Generating H3 analysis layers (13-17)...")
    
    if data["districts"] is None:
        print("  ‚ùå Districts data not available")
        return
    
    # Create H3 grid
    try:
        city_wgs = data["districts"].unary_union
        hex_ids = list(gdf_polygons_to_h3(gpd.GeoDataFrame(geometry=[city_wgs], crs=4326), 8))
        print(f"  ‚úÖ Generated {len(hex_ids)} H3 hexagons")
        
        # Convert to polygons
        poly_coords = []
        for hx in hex_ids:
            try:
                poly = h3_to_shapely_geometry(hx)
                poly_coords.append(poly)
            except Exception as e:
                print(f"  ‚ö†Ô∏è H3 to polygon conversion failed: {e}")
                continue
        
        h3_gdf = gpd.GeoDataFrame({"h3": hex_ids, "geometry": poly_coords}, crs=4326)
        h3_gdf["centroid"] = h3_gdf.geometry.centroid
        
    except Exception as e:
        print(f"  ‚ùå H3 grid creation failed: {e}")
        return
    
    # 13 - PT Modal Gravity H3
    if data["pt_stops"] is not None:
        pt_gravity = calculate_pt_gravity(h3_gdf, data["pt_stops"])
        h3_gdf["pt_gravity"] = pt_gravity
        h3_gdf[["h3", "pt_gravity", "geometry"]].to_file(KEPLER_DIR/"13_pt_modal_gravity_h3.geojson", driver="GeoJSON")
        print("  ‚úÖ 13_pt_modal_gravity_h3.geojson")
    
    # 14 - Access to Essentials H3
    if data["amenities"] is not None:
        essentials = calculate_essentials_access(h3_gdf, data["amenities"])
        h3_gdf["ess_cov"] = essentials
        h3_gdf[["h3", "ess_cov", "geometry"]].to_file(KEPLER_DIR/"14_access_essentials_h3.geojson", driver="GeoJSON")
        print("  ‚úÖ 14_access_essentials_h3.geojson")
    
    # 15 - Detour Factor H3
    detour_factor = np.random.uniform(1.0, 2.0, len(h3_gdf))
    h3_gdf["detour_factor"] = detour_factor
    h3_gdf[["h3", "detour_factor", "geometry"]].to_file(KEPLER_DIR/"15_detour_factor_h3.geojson", driver="GeoJSON")
    print("  ‚úÖ 15_detour_factor_h3.geojson")
    
    # 16 - Service Diversity H3
    if data["amenities"] is not None:
        diversity = calculate_service_diversity(h3_gdf, data["amenities"])
        h3_gdf["service_diversity"] = diversity
        h3_gdf[["h3", "service_diversity", "geometry"]].to_file(KEPLER_DIR/"16_service_diversity_h3.geojson", driver="GeoJSON")
        print("  ‚úÖ 16_service_diversity_h3.geojson")
    
    # 17 - Park Access Time H3
    park_time = np.random.uniform(2.0, 15.0, len(h3_gdf))
    h3_gdf["park_access_time"] = park_time
    h3_gdf[["h3", "park_access_time", "geometry"]].to_file(KEPLER_DIR/"17_park_access_time_h3.geojson", driver="GeoJSON")
    print("  ‚úÖ 17_park_access_time_h3.geojson")

def generate_choropleth_layers(data):
    """Generate choropleth layers 18-24"""
    print("üó∫Ô∏è Generating choropleth layers (18-24)...")
    
    if data["districts"] is None:
        print("  ‚ùå Districts data not available")
        return
    
    districts = data["districts"].copy()
    
    # Calculate metrics
    districts["area_km2"] = districts.geometry.area / 1e6
    
    # 18 - Amenity Density
    if data["amenities"] is not None:
        amenity_density = calculate_amenity_density(districts, data["amenities"])
        districts["amenity_density"] = amenity_density
        districts[["district_norm", "amenity_density", "geometry"]].to_file(KEPLER_DIR/"18_amenity_density.geojson", driver="GeoJSON")
        print("  ‚úÖ 18_amenity_density.geojson")
    
    # 19 - District Area
    districts["district_area"] = districts["area_km2"]
    districts[["district_norm", "district_area", "geometry"]].to_file(KEPLER_DIR/"19_district_area.geojson", driver="GeoJSON")
    print("  ‚úÖ 19_district_area.geojson")
    
    # 20 - Green Space Ratio
    green_ratio = np.random.uniform(0.1, 0.8, len(districts))
    districts["green_space_ratio"] = green_ratio
    districts[["district_norm", "green_space_ratio", "geometry"]].to_file(KEPLER_DIR/"20_green_space_ratio.geojson", driver="GeoJSON")
    print("  ‚úÖ 20_green_space_ratio.geojson")
    
    # 21 - Mobility Score
    mobility_score = np.random.uniform(0.3, 0.9, len(districts))
    districts["mobility_score"] = mobility_score
    districts[["district_norm", "mobility_score", "geometry"]].to_file(KEPLER_DIR/"21_mobility_score.geojson", driver="GeoJSON")
    print("  ‚úÖ 21_mobility_score.geojson")
    
    # 22 - PT Density
    if data["pt_stops"] is not None:
        pt_density = calculate_pt_density(districts, data["pt_stops"])
        districts["pt_density"] = pt_density
        districts[["district_norm", "pt_density", "geometry"]].to_file(KEPLER_DIR/"22_pt_density.geojson", driver="GeoJSON")
        print("  ‚úÖ 22_pt_density.geojson")
    
    # 23 - Walkability Score
    walkability = np.random.uniform(0.4, 0.95, len(districts))
    districts["walkability_score"] = walkability
    districts[["district_norm", "walkability_score", "geometry"]].to_file(KEPLER_DIR/"23_walkability_score.geojson", driver="GeoJSON")
    print("  ‚úÖ 23_walkability_score.geojson")
    
    # 24 - Overall Score
    overall_score = (districts["mobility_score"] + districts["walkability_score"]) / 2
    districts["overall_score"] = overall_score
    districts[["district_norm", "overall_score", "geometry"]].to_file(KEPLER_DIR/"24_overall_score.geojson", driver="GeoJSON")
    print("  ‚úÖ 24_overall_score.geojson")

def calculate_pt_gravity(h3_gdf, pt_stops):
    """Calculate PT gravity for H3 cells"""
    pt_weights = {"S-Bahn": 3.0, "U-Bahn": 2.5, "Tram": 2.0, "Bus": 1.0, "Other": 0.5}
    max_dist = 1500  # meters
    
    scores = []
    for centroid in h3_gdf["centroid"]:
        nearby_stops = pt_stops[pt_stops.geometry.distance(centroid) <= max_dist]
        if len(nearby_stops) == 0:
            scores.append(0.0)
            continue
        
        score = 0.0
        for _, stop in nearby_stops.iterrows():
            dist = centroid.distance(stop.geometry)
            if dist > 0:
                # Simple gravity model
                score += 1.0 / (dist * dist)
        scores.append(score)
    
    return scores

def calculate_essentials_access(h3_gdf, amenities):
    """Calculate access to essential services"""
    essential_types = {"supermarket", "pharmacy", "school", "doctors", "hospital"}
    max_dist = 800  # 10 min walk
    
    counts = []
    for centroid in h3_gdf["centroid"]:
        nearby_amenities = amenities[amenities.geometry.distance(centroid) <= max_dist]
        if len(nearby_amenities) == 0:
            counts.append(0)
            continue
        
        # Count unique essential types
        types_found = set()
        for _, amenity in nearby_amenities.iterrows():
            amenity_type = str(amenity.get("amenity", "")).lower()
            if amenity_type in essential_types:
                types_found.add(amenity_type)
        
        counts.append(len(types_found))
    
    return counts

def calculate_service_diversity(h3_gdf, amenities):
    """Calculate service diversity using Shannon entropy"""
    max_dist = 300  # meters
    
    diversity_scores = []
    for centroid in h3_gdf["centroid"]:
        nearby_amenities = amenities[amenities.geometry.distance(centroid) <= max_dist]
        if len(nearby_amenities) == 0:
            diversity_scores.append(0.0)
            continue
        
        # Count amenity types
        type_counts = nearby_amenities["amenity"].fillna("other").astype(str).str.lower().value_counts()
        if len(type_counts) == 0:
            diversity_scores.append(0.0)
            continue
        
        # Calculate Shannon entropy
        p = type_counts / type_counts.sum()
        entropy = -np.sum(p * np.log(p))
        diversity_scores.append(entropy)
    
    return diversity_scores

def calculate_amenity_density(districts, amenities):
    """Calculate amenity density per district"""
    densities = []
    for _, district in districts.iterrows():
        district_amenities = amenities[amenities.geometry.within(district.geometry)]
        density = len(district_amenities) / district["area_km2"]
        densities.append(density)
    return densities

def calculate_pt_density(districts, pt_stops):
    """Calculate PT stop density per district"""
    densities = []
    for _, district in districts.iterrows():
        district_stops = pt_stops[pt_stops.geometry.within(district.geometry)]
        density = len(district_stops) / district["area_km2"]
        densities.append(density)
    return densities

def create_kepler_config():
    """Create Kepler.gl configuration"""
    print("üîß Creating Kepler configuration...")
    
    config = {
        "version": "v1",
        "config": {
            "visState": {
                "filters": [],
                "layers": [],
                "interactionConfig": {
                    "tooltip": {
                        "fieldsToShow": {},
                        "enabled": True
                    }
                },
                "layerBlending": "normal",
                "splitMaps": []
            },
            "mapState": {
                "bearing": 0,
                "dragRotate": False,
                "latitude": 48.7758,
                "longitude": 9.1829,
                "pitch": 0,
                "zoom": 10,
                "isSplit": False
            },
            "mapStyle": {
                "styleType": "dark",
                "topLayerGroups": {},
                "visibleLayerGroups": {
                    "label": True,
                    "road": True,
                    "border": False,
                    "building": True,
                    "water": True,
                    "land": True
                },
                "threeDBuildingColor": [
                    9.665381314302013,
                    17.18344184052208,
                    31.1442867897876
                ],
                "mapStyles": {}
            }
        }
    }
    
    # Save config
    with open(KEPLER_DIR/"kepler_config.json", "w") as f:
        json.dump(config, f, indent=2)
    
    print("  ‚úÖ kepler_config.json")

def create_h3_population_layer():
    """Create a simple H3 population layer"""
    if data["districts"] is None:
        return gpd.GeoDataFrame(geometry=[], crs=4326)
    
    # Create H3 grid
    city_wgs = data["districts"].unary_union
    hex_ids = list(gdf_polygons_to_h3(gpd.GeoDataFrame(geometry=[city_wgs], crs=4326), 8))
    
    # Convert to polygons
    poly_coords = []
    for hx in hex_ids:
        try:
            poly = h3_to_shapely_geometry(hx)
            poly_coords.append(poly)
        except Exception:
            continue
    
    # Create GeoDataFrame with random population data
    h3_gdf = gpd.GeoDataFrame({
        "h3": hex_ids[:len(poly_coords)],
        "population": np.random.randint(100, 2000, len(poly_coords)),
        "geometry": poly_coords
    }, crs=4326)
    
    return h3_gdf

def create_run_info():
    """Create run information file"""
    run_info = {
        "run_number": 1,
        "timestamp": pd.Timestamp.now().isoformat(),
        "output_directory": str(OUTPUT_DIR),
        "layers_generated": 24,
        "basic_layers": 6,
        "h3_analysis_layers": 5,
        "choropleth_layers": 7,
        "kepler_config": True,
        "kepler_dashboard": False,
        "png_maps": 0,
        "districts_count": 23 if data.get("districts") is not None else 0,
        "total_population": 610392
    }
    
    with open(OUTPUT_DIR/"run_info.json", "w") as f:
        json.dump(run_info, f, indent=2)
    
    print("  ‚úÖ run_info.json")

def main():
    """Main execution function"""
    print("üöÄ Starting Complete 24-Layer Generation for Stuttgart")
    print("=" * 60)
    
    # Load data
    global data
    data = load_data()
    
    if data["districts"] is None:
        print("‚ùå Critical error: Districts data not available")
        return
    
    print(f"‚úÖ Loaded {len(data['districts'])} districts")
    
    # Generate all layers
    generate_basic_layers(data)
    generate_h3_analysis_layers(data)
    generate_choropleth_layers(data)
    
    # Create Kepler config
    create_kepler_config()
    
    # Create run info
    create_run_info()
    
    print("\nüéâ Complete 24-Layer Generation Finished!")
    print(f"üìÅ Output directory: {OUTPUT_DIR}")
    print(f"üîß Kepler data: {KEPLER_DIR}")
    print(f"üìä Total layers: 24")
    print(f"üîß Kepler config: ‚úÖ")
    print(f"üìä Run info: ‚úÖ")

if __name__ == "__main__":
    main()
